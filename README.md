# LoreSmith ğŸ”®  
*An AI-powered semantic search assistant for Dungeons & Dragons 5e lore*

---

## ğŸ“– Introduction
**LoreSmith** is an AI-driven semantic search and retrieval system that helps Dungeon Masters (DMs) and players quickly uncover rules, spells, and monsters from the **Dungeons & Dragons 5e System Reference Document (SRD)**.

Traditional keyword searches often fail in fast-paced sessions. LoreSmith solves this by combining **embeddings, hybrid search, reranking, and generative summarization** to provide **fast, accurate, and citation-grounded answers**.

---

## ğŸ¯ Objectives
- Build a multi-layer **RAG pipeline** (embedding, search, generative).  
- Use public datasets of **D&D 5e spells and monsters**.  
- Support natural language queries (e.g., *â€œWhich monsters are the strongest?â€*).  
- Provide structured, user-friendly answers (tables, bullet summaries).  
- Showcase both **retrieval evidence** and **final AI-generated synthesis**.  

---

## ğŸ—ï¸ System Design

LoreSmith is designed around a **three-layer architecture**:

### 1. Embedding Layer
- Embeds chunks of SRD text using **SentenceTransformers** (`all-MiniLM-L6-v2`).  
- Metadata enriched: `doc_type`, `CR`, spell level, resistances, immunities, environments.  
- Stored in **ChromaDB** as the vector index.  

### 2. Search Layer
- **BM25 keyword search** for lexical grounding.  
- **Chroma vector search** for semantic recall.  
- **Fusion + optional reranking** using a cross-encoder.  
- **Structured monster fallback**:
  - Detects monster queries explicitly.
  - Filters by **CR range, resistances, immunities, environments**.  
  - Expands synonyms (e.g., *swamps â†’ swamp, bog, marsh*).  

### 3. Generative Layer
- Retrieved chunks are passed to **OpenAI GPT models**.  
- Prompt engineering enforces *â€œAnswer only from contextâ€*.  
- Produces:
  - Narrative summaries.  
  - Bullet points.  
  - Markdown tables (e.g., CR, resistances, environments).  

---

## âš™ï¸ Implementation

- **Environment**: Jupyter Notebook (Python 3.12, Anaconda).  
- **Libraries**:  
  - `chromadb` â€“ persistent vector DB  
  - `sentence-transformers` â€“ embeddings  
  - `rank_bm25` â€“ BM25 lexical retrieval  
  - `openai` â€“ LLM generation  
  - `ipywidgets`, `IPython.display` â€“ styled notebook outputs  

- **Datasets**:  
  - [D&D 5e Spells CSV](https://github.com/wjsutton/games_night_viz/blob/main/challenges/9_bonus_challenges/202206_datafamcon_dnd/dnd-spells.csv)  
  - [D&D 5e Monsters CSV](https://github.com/wjsutton/games_night_viz/blob/main/challenges/9_bonus_challenges/202206_datafamcon_dnd/dnd_monsters.csv)  

- **Output Style**:  
  - Two panels per query:  
    1. ğŸ” **Search Layer â€” Top 3** (retrieval evidence).  
    2. âœ¨ **Generation Layer â€” Final Answer** (synthesized output).  

---

## ğŸ” Example Queries & Outputs

### Query 1: *â€œIs there a swamps monster?â€*  
- **Search Layer**: Retrieved *Nilbog* and *Boggle*.  
- **Generation Layer**: Summarized traits, CR, and swamp environments.  

### Query 2: *â€œWhich monsters are the strongest?â€*  
- **Search Layer**: Retrieved *Tarrasque, Tiamat, Demogorgon*.  
- **Generation Layer**: Explained legendary resistances and provided CR table.  

### Query 3: *â€œWhat are the most interesting spells?â€*  
- **Search Layer**: Retrieved *Find the Path, Prismatic Wall, Identify*.  
- **Generation Layer**: Summarized effects in structured Markdown table.  

*(See `/screenshots/` for Search + Generation panels.)*

---

## ğŸš§ Challenges
- **Library conflicts**: Needed `tf-keras` to resolve incompatibility between `Transformers` and Keras 3.  
- **Metadata issues**: ChromaDB required flattening list fields (resistances, immunities).  
- **Sparse monster retrieval**: Initially over-retrieved spells. Fixed with intent detection + structured fallbacks.  
- **LLM hallucinations**: Controlled via grounding prompts and explicit instructions.  

---

## ğŸ“š Lessons Learned
- Hybrid retrieval (BM25 + embeddings) outperforms single-method approaches.  
- Metadata-driven filtering (CR, environment, resistances) is crucial for niche datasets.  
- Prompt engineering is essential to prevent LLM hallucinations.  
- Transparent outputs (showing retrieval + synthesis) build trust in generative systems.  

---

## âœ… Conclusion
*LoreSmith* demonstrates how **RAG pipelines** can be applied to a fantasy RPG domain, making the complex **D&D 5e SRD** accessible through natural language. Dungeon Masters and players can now quickly query monsters, spells, and rules with structured, accurate, and context-grounded answers.  

---

## ğŸ“ Appendix
- ğŸ“‚ **Notebook**: [`LoreSmith.ipynb`](./LoreSmith.ipynb)  
- ğŸ–¼ï¸ **Screenshots**: See `/screenshots/` folder for all evaluation queries.  

---

## ğŸ§™ Credits
- Datasets: [Kaggle D&D 5e Data](https://www.kaggle.com/)  
- Embeddings: [SentenceTransformers](https://www.sbert.net/)  
- Vector Store: [ChromaDB](https://www.trychroma.com/)  
- Generation: [OpenAI GPT](https://openai.com/)  

---

